#!/usr/bin/env python3
"""
SecureOS v5.0.0 - Advanced Malware Sandbox
Hardware-isolated malware analysis and detonation chamber
"""

import os
import sys
import json
import time
import hashlib
import argparse
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional


class MalwareSandbox:
    """Advanced malware analysis sandbox with hardware isolation"""
    
    def __init__(self, sandbox_dir: str = "/var/lib/secureos/sandbox"):
        self.sandbox_dir = Path(sandbox_dir)
        self.sandbox_dir.mkdir(parents=True, exist_ok=True)
        
        self.reports_dir = self.sandbox_dir / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        self.samples_dir = self.sandbox_dir / "samples"
        self.samples_dir.mkdir(exist_ok=True)
        
        self.config = self._load_config()
    
    def _load_config(self) -> dict:
        """Load sandbox configuration"""
        return {
            'isolation_type': 'vm',  # vm, container, or firejail
            'network_enabled': False,
            'internet_simulation': True,
            'execution_timeout': 300,  # 5 minutes
            'memory_limit_mb': 2048,
            'cpu_limit_percent': 50,
            'auto_submit_threats': True,
            'yara_rules_enabled': True
        }
    
    def static_analysis(self, file_path: Path) -> Dict:
        """Perform static analysis on file"""
        print(f"Performing static analysis on {file_path.name}...")
        
        analysis = {
            'file_info': {},
            'hashes': {},
            'strings': [],
            'pe_info': None,
            'signatures': [],
            'entropy': 0.0
        }
        
        # File info
        stat_info = os.stat(file_path)
        analysis['file_info'] = {
            'name': file_path.name,
            'size': stat_info.st_size,
            'created': datetime.fromtimestamp(stat_info.st_ctime).isoformat(),
            'modified': datetime.fromtimestamp(stat_info.st_mtime).isoformat()
        }
        
        # Calculate hashes
        with open(file_path, 'rb') as f:
            content = f.read()
            analysis['hashes'] = {
                'md5': hashlib.md5(content).hexdigest(),
                'sha1': hashlib.sha1(content).hexdigest(),
                'sha256': hashlib.sha256(content).hexdigest()
            }
        
        # Extract strings
        try:
            result = subprocess.run(
                ['strings', str(file_path)],
                capture_output=True,
                text=True,
                timeout=30
            )
            strings = [s for s in result.stdout.split('\n') if len(s) > 4]
            analysis['strings'] = strings[:100]  # First 100 strings
            
            # Look for suspicious strings
            suspicious_keywords = [
                'password', 'admin', 'cmd.exe', 'powershell', 'http://',
                'https://', 'eval', 'exec', 'system', 'shell', 'exploit',
                'payload', 'backdoor', 'rootkit', 'keylog'
            ]
            
            analysis['suspicious_strings'] = [
                s for s in strings 
                if any(kw in s.lower() for kw in suspicious_keywords)
            ][:50]
        except:
            pass
        
        # Calculate entropy (high entropy = possibly packed/encrypted)
        try:
            analysis['entropy'] = self._calculate_entropy(content)
            if analysis['entropy'] > 7.0:
                analysis['signatures'].append('High entropy - possibly packed or encrypted')
        except:
            pass
        
        # File type detection
        try:
            result = subprocess.run(
                ['file', '-b', str(file_path)],
                capture_output=True,
                text=True,
                timeout=10
            )
            analysis['file_type'] = result.stdout.strip()
        except:
            pass
        
        return analysis
    
    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of data"""
        import math
        
        if not data:
            return 0.0
        
        # Count byte frequencies
        freq = {}
        for byte in data:
            freq[byte] = freq.get(byte, 0) + 1
        
        # Calculate entropy
        entropy = 0.0
        data_len = len(data)
        for count in freq.values():
            p = count / data_len
            entropy -= p * math.log2(p)
        
        return entropy
    
    def dynamic_analysis(self, file_path: Path) -> Dict:
        """Perform dynamic analysis (execute in sandbox)"""
        print(f"Performing dynamic analysis on {file_path.name}...")
        
        analysis = {
            'executed': False,
            'start_time': datetime.now().isoformat(),
            'end_time': None,
            'duration': 0,
            'process_info': {},
            'network_activity': [],
            'file_operations': [],
            'registry_changes': [],
            'behavior': []
        }
        
        # Create isolated sandbox environment
        sandbox_id = hashlib.md5(f"{file_path.name}{time.time()}".encode()).hexdigest()[:16]
        sandbox_vm = self.sandbox_dir / f"sandbox-{sandbox_id}"
        sandbox_vm.mkdir(exist_ok=True)
        
        try:
            # Execute in sandbox based on isolation type
            if self.config['isolation_type'] == 'firejail':
                analysis = self._execute_in_firejail(file_path, sandbox_vm)
            elif self.config['isolation_type'] == 'container':
                analysis = self._execute_in_container(file_path, sandbox_vm)
            else:
                analysis = self._execute_in_vm(file_path, sandbox_vm)
            
            analysis['executed'] = True
            
        except Exception as e:
            analysis['error'] = str(e)
            print(f"❌ Dynamic analysis failed: {e}")
        
        analysis['end_time'] = datetime.now().isoformat()
        
        return analysis
    
    def _execute_in_firejail(self, file_path: Path, sandbox_dir: Path) -> Dict:
        """Execute file in Firejail sandbox"""
        result = {
            'method': 'firejail',
            'network_activity': [],
            'file_operations': [],
            'behavior': []
        }
        
        # Prepare firejail command
        firejail_cmd = [
            'firejail',
            '--private=' + str(sandbox_dir),
            '--net=none' if not self.config['network_enabled'] else '--net=eth0',
            '--caps.drop=all',
            '--seccomp',
            '--noroot',
            '--rlimit-as=' + str(self.config['memory_limit_mb'] * 1024 * 1024),
            str(file_path)
        ]
        
        try:
            # Execute with timeout
            proc = subprocess.run(
                firejail_cmd,
                capture_output=True,
                text=True,
                timeout=self.config['execution_timeout']
            )
            
            result['exit_code'] = proc.returncode
            result['stdout'] = proc.stdout
            result['stderr'] = proc.stderr
            
            # Analyze behavior
            if 'denied' in proc.stderr.lower():
                result['behavior'].append('Attempted restricted operation')
            
            if proc.returncode != 0:
                result['behavior'].append(f'Abnormal exit code: {proc.returncode}')
            
        except subprocess.TimeoutExpired:
            result['behavior'].append('Execution timeout - possible infinite loop')
        
        return result
    
    def _execute_in_container(self, file_path: Path, sandbox_dir: Path) -> Dict:
        """Execute file in Docker container"""
        result = {
            'method': 'docker',
            'network_activity': [],
            'file_operations': [],
            'behavior': []
        }
        
        # Use minimal Alpine Linux container for isolation
        docker_cmd = [
            'docker', 'run',
            '--rm',
            '--network', 'none' if not self.config['network_enabled'] else 'bridge',
            '--memory', f'{self.config["memory_limit_mb"]}m',
            '--cpus', str(self.config['cpu_limit_percent'] / 100),
            '--security-opt', 'no-new-privileges',
            '--cap-drop', 'ALL',
            '-v', f'{file_path}:/sample:ro',
            'alpine:latest',
            '/sample'
        ]
        
        try:
            proc = subprocess.run(
                docker_cmd,
                capture_output=True,
                text=True,
                timeout=self.config['execution_timeout']
            )
            
            result['exit_code'] = proc.returncode
            result['stdout'] = proc.stdout
            result['stderr'] = proc.stderr
            
        except subprocess.TimeoutExpired:
            result['behavior'].append('Execution timeout')
        except FileNotFoundError:
            result['error'] = 'Docker not available'
        
        return result
    
    def _execute_in_vm(self, file_path: Path, sandbox_dir: Path) -> Dict:
        """Execute file in QEMU VM (most isolated)"""
        result = {
            'method': 'qemu_vm',
            'network_activity': [],
            'file_operations': [],
            'behavior': ['VM execution not implemented in demo']
        }
        
        # In production, this would:
        # 1. Create snapshot of clean VM
        # 2. Copy sample to VM
        # 3. Execute sample
        # 4. Monitor with QEMU hooks
        # 5. Restore from snapshot
        
        return result
    
    def yara_scan(self, file_path: Path) -> List[Dict]:
        """Scan file with YARA rules"""
        matches = []
        
        # Sample YARA rules (in production, load from file)
        sample_rules = {
            'suspicious_api': ['CreateRemoteThread', 'WriteProcessMemory', 'VirtualAllocEx'],
            'network_indicators': ['URLDownloadToFile', 'InternetOpen', 'HttpSendRequest'],
            'persistence': ['RegSetValue', 'CreateService', 'WinExec'],
            'credential_theft': ['LsaEnumerateLogonSessions', 'SamConnect', 'mimikatz']
        }
        
        try:
            with open(file_path, 'rb') as f:
                content = f.read().decode('utf-8', errors='ignore')
            
            for rule_name, indicators in sample_rules.items():
                for indicator in indicators:
                    if indicator in content:
                        matches.append({
                            'rule': rule_name,
                            'indicator': indicator,
                            'severity': 'high' if rule_name in ['credential_theft', 'persistence'] else 'medium'
                        })
        except:
            pass
        
        return matches
    
    def analyze(self, file_path: str) -> str:
        """Complete malware analysis pipeline"""
        file_path = Path(file_path)
        
        if not file_path.exists():
            print(f"❌ File not found: {file_path}")
            return None
        
        print("=" * 70)
        print(f"SecureOS Malware Sandbox - Analyzing: {file_path.name}")
        print("=" * 70)
        
        # Generate analysis ID
        analysis_id = hashlib.sha256(f"{file_path.name}{time.time()}".encode()).hexdigest()[:16]
        
        # Copy sample to sandbox
        sample_copy = self.samples_dir / f"{analysis_id}_{file_path.name}"
        subprocess.run(['cp', str(file_path), str(sample_copy)])
        
        # Full analysis
        report = {
            'analysis_id': analysis_id,
            'timestamp': datetime.now().isoformat(),
            'sample': str(file_path),
            'static_analysis': self.static_analysis(sample_copy),
            'yara_matches': self.yara_scan(sample_copy),
            'dynamic_analysis': None,
            'threat_score': 0,
            'verdict': 'unknown'
        }
        
        # Dynamic analysis (optional - can be dangerous)
        perform_dynamic = input("\nPerform dynamic analysis? This will EXECUTE the sample. (yes/no): ")
        if perform_dynamic.lower() == 'yes':
            report['dynamic_analysis'] = self.dynamic_analysis(sample_copy)
        
        # Calculate threat score
        score = 0
        
        # Static analysis scoring
        if report['static_analysis']['entropy'] > 7.0:
            score += 20
        
        if len(report['static_analysis'].get('suspicious_strings', [])) > 10:
            score += 30
        
        # YARA matches scoring
        for match in report['yara_matches']:
            if match['severity'] == 'high':
                score += 25
            elif match['severity'] == 'medium':
                score += 15
        
        # Dynamic analysis scoring
        if report['dynamic_analysis']:
            behavior_count = len(report['dynamic_analysis'].get('behavior', []))
            score += min(behavior_count * 10, 40)
        
        report['threat_score'] = min(score, 100)
        
        # Determine verdict
        if score >= 70:
            report['verdict'] = 'malicious'
        elif score >= 40:
            report['verdict'] = 'suspicious'
        else:
            report['verdict'] = 'likely_benign'
        
        # Save report
        report_file = self.reports_dir / f"report_{analysis_id}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Display summary
        print("\n" + "=" * 70)
        print("ANALYSIS SUMMARY")
        print("=" * 70)
        print(f"Analysis ID: {analysis_id}")
        print(f"Threat Score: {report['threat_score']}/100")
        print(f"Verdict: {report['verdict'].upper()}")
        print(f"\nFile Hashes:")
        for hash_type, hash_value in report['static_analysis']['hashes'].items():
            print(f"  {hash_type.upper()}: {hash_value}")
        
        if report['yara_matches']:
            print(f"\nYARA Matches: {len(report['yara_matches'])}")
            for match in report['yara_matches'][:5]:
                print(f"  - {match['rule']}: {match['indicator']}")
        
        print(f"\nFull report: {report_file}")
        print("=" * 70)
        
        return analysis_id
    
    def list_reports(self):
        """List all analysis reports"""
        reports = list(self.reports_dir.glob("report_*.json"))
        
        if not reports:
            print("No analysis reports found.")
            return
        
        print(f"\nFound {len(reports)} analysis reports:\n")
        
        for report_file in sorted(reports, reverse=True)[:20]:
            with open(report_file, 'r') as f:
                report = json.load(f)
            
            print(f"[{report['verdict'].upper()}] {report['analysis_id']}")
            print(f"  Sample: {Path(report['sample']).name}")
            print(f"  Timestamp: {report['timestamp']}")
            print(f"  Threat Score: {report['threat_score']}/100\n")


def main():
    parser = argparse.ArgumentParser(description='SecureOS Malware Sandbox')
    parser.add_argument('command', choices=['analyze', 'report', 'list', 'clean'])
    parser.add_argument('--file', type=str, help='File to analyze')
    parser.add_argument('--id', type=str, help='Analysis ID for report')
    
    args = parser.parse_args()
    
    sandbox = MalwareSandbox()
    
    if args.command == 'analyze':
        if not args.file:
            print("Error: --file required")
            sys.exit(1)
        
        sandbox.analyze(args.file)
    
    elif args.command == 'report':
        if not args.id:
            print("Error: --id required")
            sys.exit(1)
        
        report_file = sandbox.reports_dir / f"report_{args.id}.json"
        if report_file.exists():
            with open(report_file, 'r') as f:
                print(json.dumps(json.load(f), indent=2))
        else:
            print(f"Report not found: {args.id}")
    
    elif args.command == 'list':
        sandbox.list_reports()
    
    elif args.command == 'clean':
        confirm = input("Delete all sandbox data? (yes/no): ")
        if confirm.lower() == 'yes':
            import shutil
            shutil.rmtree(sandbox.sandbox_dir)
            print("Sandbox data cleaned.")


if __name__ == '__main__':
    main()
